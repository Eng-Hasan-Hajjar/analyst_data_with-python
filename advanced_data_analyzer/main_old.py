import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import pandas as pd
import numpy as np
from numpy import random
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
import seaborn as sns
import io
import sys
import os
import warnings
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.cluster import KMeans, DBSCAN
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.font_manager as fm
from datetime import datetime, timedelta
import json
import csv
import sqlite3
import threading
import time
import webbrowser
from PIL import Image, ImageTk
import requests
import hashlib
import zipfile
import tempfile
import platform
import calendar
from dateutil import parser
import re

warnings.filterwarnings('ignore')

# ------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© -------------------
class AdvancedDataAnalyzer:
    def __init__(self):
        self.version = "3.0.0"
        self.author = "Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"
        self.support_email = "support@dataanalysis.com"
        
    def get_system_info(self):
        return {
            "platform": platform.system(),
            "version": platform.version(),
            "python_version": platform.python_version(),
            "processor": platform.processor()
        }

analyzer = AdvancedDataAnalyzer()

# ------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© -------------------
try:
    arabic_font = fm.FontProperties(fname='arial.ttf')
except:
    arabic_font = None

# ------------------- Ø§Ù„Ø­Ø§Ù„Ø© ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© -------------------
is_arabic = True
is_dark_mode = True
data_frame = None
current_plot = None
user_notes = {}
current_analysis_history = []
ml_models = {}
data_snapshots = {}
analysis_results = {}
current_session_id = None

user_preferences = {
    "language": "arabic",
    "theme": "dark",
    "font_size": 12,
    "auto_save": False,
    "default_chart_style": "seaborn",
    "animation_effects": True,
    "tooltips": True,
    "auto_update": True,
    "backup_interval": 10,
    "export_quality": "high",
    "recent_files": [],
    "max_recent_files": 10,
    "default_analysis": "basic_stats",
    "data_preview_rows": 15,
    "chart_colors": "viridis",
    "number_format": "comma",
    "date_format": "YYYY-MM-DD",
    "timezone": "Asia/Riyadh"
}

# ------------------- Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø­Ø³Ø¨ Ø§Ù„Ø³Ù…Ø© -------------------
COLORS = {
    "dark": {
        "bg": "#1e1e2f", "frame_bg": "#2a2a40", "text": "white",
        "button_bg": "#3b8ad8", "accent": "#6a6a9c", "success": "#4caf50",
        "warning": "#ff9800", "error": "#f44336", "highlight": "#ffd700",
        "header": "#343456", "border": "#4a4a6a", "card": "#2d2d44"
    },
    "light": {
        "bg": "#f5f5f5", "frame_bg": "#ffffff", "text": "#333333",
        "button_bg": "#2196F3", "accent": "#e0e0e0", "success": "#4CAF50",
        "warning": "#FFC107", "error": "#F44336", "highlight": "#FFEB3B",
        "header": "#e8e8e8", "border": "#d0d0d0", "card": "#f8f9fa"
    }
}

# ------------------- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© -------------------
class AdvancedDataAnalysisDB:
    def __init__(self):
        self.conn = sqlite3.connect('advanced_data_analysis.db', check_same_thread=False)
        self.create_tables()
    
    def create_tables(self):
        cursor = self.conn.cursor()
        
        tables = [
            '''CREATE TABLE IF NOT EXISTS analysis_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_name TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                data_shape TEXT, analysis_type TEXT, parameters TEXT)''',
            
            '''CREATE TABLE IF NOT EXISTS saved_models (
                id INTEGER PRIMARY KEY AUTOINCREMENT, model_name TEXT,
                model_type TEXT, accuracy REAL, parameters TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''',
            
            '''CREATE TABLE IF NOT EXISTS data_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT, session_id INTEGER,
                snapshot_name TEXT, data_hash TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''',
            
            '''CREATE TABLE IF NOT EXISTS user_notes (
                id INTEGER PRIMARY KEY AUTOINCREMENT, session_id INTEGER,
                note_text TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''',
            
            '''CREATE TABLE IF NOT EXISTS analysis_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT, session_id INTEGER,
                action_type TEXT, action_details TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)'''
        ]
        
        for table in tables:
            cursor.execute(table)
        self.conn.commit()
    
    def save_analysis_session(self, session_name, data_shape, analysis_type, parameters):
        cursor = self.conn.cursor()
        cursor.execute('''INSERT INTO analysis_sessions (session_name, data_shape, analysis_type, parameters)
                         VALUES (?, ?, ?, ?)''', 
                      (session_name, str(data_shape), analysis_type, json.dumps(parameters)))
        self.conn.commit()
        return cursor.lastrowid

advanced_db = AdvancedDataAnalysisDB()

# ------------------- Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© -------------------
class DataAnalysisFeatures:
    @staticmethod
    def detect_data_quality_issues(df):
        """ÙƒØ´Ù Ù…Ø´Ø§ÙƒÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        issues = []
        
        if df is None:
            return ["Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„"]
        
        # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        missing = df.isnull().sum()
        if missing.sum() > 0:
            issues.append(f"Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {missing.sum()} Ù‚ÙŠÙ…Ø©")
        
        # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        duplicates = df.duplicated().sum()
        if duplicates > 0:
            issues.append(f"Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {duplicates} ØµÙ")
        
        # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()
            if outliers > 0:
                issues.append(f"Ù‚ÙŠÙ… Ù…ØªØ·Ø±ÙØ© ÙÙŠ {col}: {outliers} Ù‚ÙŠÙ…Ø©")
        
        return issues

    @staticmethod
    def automated_data_cleaning(df):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¢Ù„ÙŠ"""
        if df is None:
            return None
            
        df_clean = df.copy()
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        df_clean = df_clean.drop_duplicates()
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        for col in df_clean.columns:
            if df_clean[col].dtype in ['int64', 'float64']:
                df_clean[col].fillna(df_clean[col].median(), inplace=True)
            else:
                df_clean[col].fillna(df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown', inplace=True)
        
        return df_clean

    @staticmethod
    def create_advanced_chart(df, chart_type, x_col, y_col=None):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©"""
        if df is None or df.empty:
            return None
            
        fig, ax = plt.subplots(figsize=(10, 6))
        
        try:
            if chart_type == "heatmap":
                corr = df.select_dtypes(include=[np.number]).corr()
                sns.heatmap(corr, annot=True, ax=ax)
            elif chart_type == "pairplot":
                sns.pairplot(df.select_dtypes(include=[np.number]))
            elif chart_type == "violin" and y_col:
                sns.violinplot(data=df, x=x_col, y=y_col, ax=ax)
            elif chart_type == "swarm" and y_col:
                sns.swarmplot(data=df, x=x_col, y=y_col, ax=ax)
            else:
                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                df.select_dtypes(include=[np.number]).iloc[:,0].plot(kind='hist', ax=ax)
        except Exception as e:
            print(f"Error creating chart: {e}")
            return None
        
        return fig

    @staticmethod
    def time_series_analysis(df, date_col, value_col):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        if df is None or date_col not in df.columns or value_col not in df.columns:
            return {}
            
        try:
            df[date_col] = pd.to_datetime(df[date_col])
            df = df.set_index(date_col)
            
            analysis = {
                'monthly_mean': df[value_col].resample('M').mean(),
                'trend': df[value_col].rolling(window=30).mean(),
                'seasonality': df[value_col].groupby(df.index.month).mean()
            }
            
            return analysis
        except:
            return {}

    @staticmethod
    def feature_engineering(df):
        """Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        if df is None:
            return None
            
        df_engineered = df.copy()
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            try:
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
                df_engineered[f'{col}_squared'] = df[col] ** 2
                df_engineered[f'{col}_log'] = np.log1p(np.abs(df[col]) + 1)  # ØªØ¬Ù†Ø¨ Ø§Ù„Ø£ØµÙØ§Ø± ÙˆØ§Ù„Ø³Ø§Ù„Ø¨Ø©
                df_engineered[f'{col}_zscore'] = (df[col] - df[col].mean()) / df[col].std()
            except:
                continue
        
        return df_engineered

features = DataAnalysisFeatures()

# ------------------- Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø© -------------------
def load_file():
    global data_frame, current_session_id
    file = filedialog.askopenfilename(
        title="Ø§Ø®ØªØ± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª" if is_arabic else "Select Data File",
        filetypes=[
            ("Excel Files", "*.xlsx *.xls"), 
            ("CSV Files", "*.csv"),
            ("JSON Files", "*.json"),
            ("Text Files", "*.txt"),
            ("All Files", ".")
        ]
    )
    
    if file:
        try:
            update_status("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù..." if is_arabic else "Loading file...")
            
            file_size = os.path.getsize(file) / (1024 * 1024)
            if file_size > 50:
                if not messagebox.askyesno("ØªØ­Ø°ÙŠØ±", f"Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± ({file_size:.1f} MB). Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©ØŸ"):
                    return
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            if file.endswith('.csv'):
                data_frame = pd.read_csv(file, encoding='utf-8')
            elif file.endswith('.json'):
                data_frame = pd.read_json(file)
            elif file.endswith(('.xlsx', '.xls')):
                data_frame = pd.read_excel(file)
            else:
                data_frame = pd.read_csv(file, delimiter=None, engine='python')
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
            update_recent_files_menu(file)
            update_data_preview()
            show_dataframe_in_table()
            update_all_selectors()
            
            # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø©
            current_session_id = advanced_db.save_analysis_session(
                os.path.basename(file),
                data_frame.shape,
                "data_loading",
                {"file_type": file.split('.')[-1], "rows": data_frame.shape[0], "columns": data_frame.shape[1]}
            )
            
            # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            quality_issues = features.detect_data_quality_issues(data_frame)
            if quality_issues:
                show_quality_report(quality_issues)
            
            update_status("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!" if is_arabic else "Data loaded successfully!")
            
        except Exception as e:
            update_status("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù" if is_arabic else "Failed to load file")
            messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")

def update_recent_files_menu(file=None):
    if hasattr(root, 'recent_menu'):
        root.recent_menu.delete(0, tk.END)
        for file_path in user_preferences["recent_files"]:
            root.recent_menu.add_command(
                label=os.path.basename(file_path),
                command=lambda f=file_path: load_recent_file(f)
            )
        if file and file not in user_preferences["recent_files"]:
            user_preferences["recent_files"].insert(0, file)
            if len(user_preferences["recent_files"]) > user_preferences["max_recent_files"]:
                user_preferences["recent_files"].pop()

def load_recent_file(file):
    global data_frame
    try:
        if file.endswith('.csv'):
            data_frame = pd.read_csv(file, encoding='utf-8')
        elif file.endswith('.json'):
            data_frame = pd.read_json(file)
        elif file.endswith(('.xlsx', '.xls')):
            data_frame = pd.read_excel(file)
        else:
            data_frame = pd.read_csv(file, delimiter=None, engine='python')
        
        update_data_preview()
        show_dataframe_in_table()
        update_all_selectors()
        update_status("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø­Ø¯ÙŠØ«!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")

def show_dataframe_in_table():
    if data_frame is None or 'table_frame' not in globals():
        return
    
    for widget in table_frame.winfo_children():
        widget.destroy()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Treeview Ù…Ø¹ Ø´Ø±ÙŠØ· ØªÙ…Ø±ÙŠØ±
    tree_frame = tk.Frame(table_frame)
    tree_frame.pack(fill="both", expand=True)
    
    tree_scroll = ttk.Scrollbar(tree_frame)
    tree_scroll.pack(side="right", fill="y")
    
    global data_table
    data_table = ttk.Treeview(tree_frame, yscrollcommand=tree_scroll.set, show="headings")
    data_table.pack(fill="both", expand=True)
    
    tree_scroll.config(command=data_table.yview)
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    data_table["columns"] = list(data_frame.columns)
    for col in data_frame.columns:
        data_table.heading(col, text=col)
        data_table.column(col, width=120, anchor="center")
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    for index, row in data_frame.head(1000).iterrows():
        data_table.insert("", "end", values=list(row))

def update_all_selectors():
    if data_frame is not None:
        columns = list(data_frame.columns)
        selectors = [
            'x_axis_selector', 'y_axis_selector', 'cluster_column_selector',
            'regression_x_selector', 'regression_y_selector',
            'classification_x_selector', 'classification_y_selector',
            'date_column_selector', 'value_column_selector'
        ]
        
        for selector_name in selectors:
            if selector_name in globals():
                try:
                    globals()[selector_name]['values'] = columns
                except:
                    pass

# ------------------- Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© -------------------
def show_quality_report(issues):
    """Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    report_window = tk.Toplevel(root)
    report_window.title("ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    report_window.geometry("600x400")
    
    report_text = scrolledtext.ScrolledText(report_window, font=("Arial", 12))
    report_text.pack(fill="both", expand=True, padx=10, pady=10)
    
    report_content = "ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n" + "="*50 + "\n\n"
    for issue in issues:
        report_content += f"âš ï¸ {issue}\n"
    
    report_content += f"\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„: {len(issues)}"
    report_text.insert("1.0", report_content)
    report_text.config(state="disabled")

def automated_data_cleaning():
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¢Ù„ÙŠ"""
    global data_frame
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ†Ø¸ÙŠÙ!")
        return
    
    try:
        data_frame = features.automated_data_cleaning(data_frame)
        update_data_preview()
        show_dataframe_in_table()
        update_status("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")

def advanced_statistical_analysis():
    """ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…ØªÙ‚Ø¯Ù…"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        return
    
    try:
        numeric_cols = data_frame.select_dtypes(include=[np.number]).columns
        results = {}
        
        for col in numeric_cols:
            results[col] = {
                'mean': data_frame[col].mean(),
                'median': data_frame[col].median(),
                'std': data_frame[col].std(),
                'skewness': data_frame[col].skew(),
                'kurtosis': data_frame[col].kurtosis(),
                'variance': data_frame[col].var()
            }
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù†Ø§ÙØ°Ø© Ø¬Ø¯ÙŠØ¯Ø©
        show_statistical_results(results)
        
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ: {str(e)}")

def show_statistical_results(results):
    """Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©"""
    results_window = tk.Toplevel(root)
    results_window.title("Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
    results_window.geometry("800x600")
    
    notebook = ttk.Notebook(results_window)
    notebook.pack(fill="both", expand=True, padx=10, pady=10)
    
    # ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results_frame = ttk.Frame(notebook)
    notebook.add(results_frame, text="Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    text_widget = scrolledtext.ScrolledText(results_frame, font=("Courier", 10))
    text_widget.pack(fill="both", expand=True)
    
    results_text = "Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©\n" + "="*50 + "\n\n"
    for col, stats in results.items():
        results_text += f"ğŸ“Š Ø§Ù„Ø¹Ù…ÙˆØ¯: {col}\n"
        for stat_name, value in stats.items():
            results_text += f"   {stat_name}: {value:.4f}\n"
        results_text += "\n"
    
    text_widget.insert("1.0", results_text)
    text_widget.config(state="disabled")

def correlation_analysis():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        return
    
    try:
        numeric_df = data_frame.select_dtypes(include=[np.number])
        if numeric_df.empty:
            messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
            return
        
        # Ø­Ø³Ø§Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
        correlation_matrix = numeric_df.corr()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ©
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=ax1)
        ax1.set_title('Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·')
        
        # Ø±Ø³Ù… Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
        if len(numeric_df.columns) >= 2:
            sns.scatterplot(data=numeric_df, x=numeric_df.columns[0], y=numeric_df.columns[1], ax=ax2)
            ax2.set_title('Ù…Ø®Ø·Ø· Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±')
        
        plt.tight_layout()
        plt.show()
        
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·: {str(e)}")

def time_series_analysis():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        return
    
    try:
        # Ù†Ø§ÙØ°Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        ts_window = tk.Toplevel(root)
        ts_window.title("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
        ts_window.geometry("400x200")
        
        tk.Label(ts_window, text="Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®:").pack(pady=5)
        date_selector = ttk.Combobox(ts_window)
        date_selector.pack(pady=5)
        
        tk.Label(ts_window, text="Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‚ÙŠÙ…:").pack(pady=5)
        value_selector = ttk.Combobox(ts_window)
        value_selector.pack(pady=5)
        
        date_selector['values'] = list(data_frame.columns)
        value_selector['values'] = list(data_frame.select_dtypes(include=[np.number]).columns)
        
        def run_analysis():
            date_col = date_selector.get()
            value_col = value_selector.get()
            
            if not date_col or not value_col:
                messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "ÙŠØ¬Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠÙ†!")
                return
            
            analysis = features.time_series_analysis(data_frame, date_col, value_col)
            show_time_series_results(analysis, value_col)
            ts_window.destroy()
        
        tk.Button(ts_window, text="ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„", command=run_analysis).pack(pady=10)
        
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ: {str(e)}")

def show_time_series_results(analysis, value_col):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    results_window = tk.Toplevel(root)
    results_window.title("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ")
    results_window.geometry("600x400")
    
    text_widget = scrolledtext.ScrolledText(results_window, font=("Arial", 11))
    text_widget.pack(fill="both", expand=True, padx=10, pady=10)
    
    results_text = f"Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø¹Ù…ÙˆØ¯: {value_col}\n" + "="*50 + "\n\n"
    
    for key, value in analysis.items():
        results_text += f"{key}:\n{value}\n\n"
    
    text_widget.insert("1.0", results_text)
    text_widget.config(state="disabled")

def machine_learning_predictions():
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        return
    
    try:
        ml_window = tk.Toplevel(root)
        ml_window.title("Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ")
        ml_window.geometry("500x300")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ
        tk.Label(ml_window, text="Ø§Ø®ØªØ± Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ:", font=("Arial", 12)).pack(pady=10)
        
        ml_algorithms = [
            ("Ø§Ù†Ø­Ø¯Ø§Ø± Ø®Ø·ÙŠ (Linear Regression)", "linear_regression"),
            ("ØºØ§Ø¨Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (Random Forest)", "random_forest"),
            ("Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (K-Means)", "kmeans"),
            ("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ (Logistic Regression)", "logistic_regression")
        ]
        
        algorithm_var = tk.StringVar(value="linear_regression")
        
        for text, value in ml_algorithms:
            ttk.Radiobutton(ml_window, text=text, variable=algorithm_var, value=value).pack(anchor="w", padx=20)
        
        def run_ml_analysis():
            algorithm = algorithm_var.get()
            result = run_machine_learning(algorithm)
            show_ml_results(result, algorithm)
            ml_window.destroy()
        
        tk.Button(ml_window, text="ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", command=run_ml_analysis).pack(pady=20)
        
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ: {str(e)}")

def run_machine_learning(algorithm):
    """ØªØ´ØºÙŠÙ„ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    if data_frame is None:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!"
        
    numeric_df = data_frame.select_dtypes(include=[np.number])
    if numeric_df.empty or len(numeric_df.columns) < 2:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„!"
    
    try:
        X = numeric_df.iloc[:, :-1]
        y = numeric_df.iloc[:, -1]
        
        if algorithm == "linear_regression":
            model = LinearRegression()
            model.fit(X, y)
            predictions = model.predict(X)
            r2 = r2_score(y, predictions)
            return f"Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ - RÂ²: {r2:.4f}"
        
        elif algorithm == "random_forest":
            model = RandomForestRegressor()
            model.fit(X, y)
            predictions = model.predict(X)
            r2 = r2_score(y, predictions)
            return f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØºØ§Ø¨Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© - RÂ²: {r2:.4f}"
        
        elif algorithm == "kmeans":
            model = KMeans(n_clusters=3)
            clusters = model.fit_predict(X)
            return f"Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ - Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: 3"
        
        elif algorithm == "logistic_regression":
            model = LogisticRegression()
            model.fit(X, y)
            accuracy = model.score(X, y)
            return f"Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ - Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.4f}"
        else:
            return "Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"
    
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}"

def show_ml_results(result, algorithm):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    results_window = tk.Toplevel(root)
    results_window.title("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ")
    results_window.geometry("500x200")
    
    tk.Label(results_window, text=f"Ù†ØªØ§Ø¦Ø¬ {algorithm}", font=("Arial", 14, "bold")).pack(pady=10)
    tk.Label(results_window, text=result, font=("Arial", 12)).pack(pady=10)
    tk.Button(results_window, text="Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", command=lambda: save_ml_model(algorithm, result)).pack(pady=10)

def save_ml_model(algorithm, result):
    """Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
    try:
        model_data = {
            'algorithm': algorithm,
            'result': result,
            'timestamp': datetime.now().isoformat(),
            'data_shape': data_frame.shape if data_frame is not None else 'No data'
        }
        
        with open(f"model_{algorithm}{datetime.now().strftime('%Y%m%d%H%M%S')}.json", 'w', encoding='utf-8') as f:
            json.dump(model_data, f, ensure_ascii=False, indent=2)
        
        messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")

def export_dashboard():
    """ØªØµØ¯ÙŠØ± Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±!")
        return
    
    try:
        file_path = filedialog.asksaveasfilename(
            defaultextension=".html",
            filetypes=[("HTML files", ".html"), ("All files", ".*")]
        )
        
        if file_path:
            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML Ø¨Ø³ÙŠØ·
            report = create_html_report()
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(report)
            
            messagebox.showinfo("Ù†Ø¬Ø§Ø­", f"ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¥Ù„Ù‰: {file_path}")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§Ù„ØªØµØ¯ÙŠØ±: {str(e)}")

def create_html_report():
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML"""
    if data_frame is None:
        return "<html><body>Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª</body></html>"
    
    html_content = f"""
    <html>
    <head>
        <title>ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            .header {{ background: #2c3e50; color: white; padding: 20px; text-align: center; }}
            .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; }}
            table {{ width: 100%; border-collapse: collapse; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background: #f2f2f2; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</h1>
            <p>ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ ÙÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="section">
            <h2>Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</h2>
            <p>Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {data_frame.shape[0]}</p>
            <p>Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {data_frame.shape[1]}</p>
        </div>
        
        <div class="section">
            <h2>Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</h2>
            {data_frame.head().to_html() if hasattr(data_frame, 'to_html') else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª'}
        </div>
    </body>
    </html>
    """
    
    return html_content

# ------------------- Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø®Ø·Ø§Ø¡ -------------------
def advanced_feature_engineering():
    """Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­"""
    global data_frame
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­ÙˆÙŠÙ„!")
        return
    
    try:
        data_frame = features.feature_engineering(data_frame)
        update_data_preview()
        show_dataframe_in_table()
        messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ…Øª Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª: {str(e)}")

def normalize_data():
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­"""
    global data_frame
    if data_frame is not None:
        numeric_df = data_frame.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            scaler = MinMaxScaler()
            data_frame[numeric_df.columns] = scaler.fit_transform(numeric_df)
            update_data_preview()
            show_dataframe_in_table()
            messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

def standardize_data():
    """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­"""
    global data_frame
    if data_frame is not None:
        numeric_df = data_frame.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            scaler = StandardScaler()
            data_frame[numeric_df.columns] = scaler.fit_transform(numeric_df)
            update_data_preview()
            show_dataframe_in_table()
            messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ… ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

def log_transform():
    """ØªØ­ÙˆÙŠÙ„ Ù„ÙˆØºØ§Ø±ÙŠØªÙ…ÙŠ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­"""
    global data_frame
    if data_frame is not None:
        numeric_df = data_frame.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            # ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© ÙˆØ§Ù„ØµÙØ±
            numeric_df = numeric_df.apply(lambda x: x + abs(x.min()) + 1 if x.min() <= 0 else x)
            data_frame[numeric_df.columns] = np.log1p(numeric_df)
            update_data_preview()
            show_dataframe_in_table()
            messagebox.showinfo("Ù†Ø¬Ø§Ø­", "ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")

def pattern_detection():
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        return
    
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        numeric_df = data_frame.select_dtypes(include=[np.number])
        
        if not numeric_df.empty:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            trends = {}
            for col in numeric_df.columns:
                if len(numeric_df[col]) > 1:
                    try:
                        correlation = numeric_df[col].corr(pd.Series(range(len(numeric_df[col]))))
                        trends[col] = "ØªØµØ§Ø¹Ø¯ÙŠ" if correlation > 0.5 else "ØªÙ†Ø§Ø²Ù„ÙŠ" if correlation < -0.5 else "Ø«Ø§Ø¨Øª"
                    except:
                        trends[col] = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            pattern_window = tk.Toplevel(root)
            pattern_window.title("Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·")
            pattern_window.geometry("400x300")
            
            text_widget = scrolledtext.ScrolledText(pattern_window)
            text_widget.pack(fill="both", expand=True, padx=10, pady=10)
            
            results_text = "ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·\n" + "="*40 + "\n\n"
            for col, trend in trends.items():
                results_text += f"ğŸ“ˆ {col}: Ø§ØªØ¬Ø§Ù‡ {trend}\n"
            
            text_widget.insert("1.0", results_text)
            text_widget.config(state="disabled")
        else:
            messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
    
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {str(e)}")

# ------------------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø³Ù†Ø© -------------------
def create_advanced_menu():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©"""
    menubar = tk.Menu(root)
    
    # Ù‚Ø§Ø¦Ù…Ø© Ù…Ù„Ù
    file_menu = tk.Menu(menubar, tearoff=0)
    file_menu.add_command(label="ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª", command=load_file)
    file_menu.add_command(label="ØªØµØ¯ÙŠØ± Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", command=export_dashboard)
    file_menu.add_separator()
    file_menu.add_command(label="Ø®Ø±ÙˆØ¬", command=root.quit)
    menubar.add_cascade(label="Ù…Ù„Ù", menu=file_menu)
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø­Ø¯ÙŠØ«Ø©
    recent_menu = tk.Menu(file_menu, tearoff=0)
    file_menu.add_cascade(label="Ù…Ù„ÙØ§Øª Ø­Ø¯ÙŠØ«Ø©", menu=recent_menu)
    root.recent_menu = recent_menu
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¯ÙˆØ§Øª
    tools_menu = tk.Menu(menubar, tearoff=0)
    tools_menu.add_command(label="ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹", command=quick_analysis)
    tools_menu.add_command(label="ØªÙ†Ø¸ÙŠÙ Ø¢Ù„ÙŠ", command=automated_data_cleaning)
    tools_menu.add_command(label="ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ", command=advanced_statistical_analysis)
    menubar.add_cascade(label="Ø£Ø¯ÙˆØ§Øª", menu=tools_menu)
    
    # Ù‚Ø§Ø¦Ù…Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©
    help_menu = tk.Menu(menubar, tearoff=0)
    help_menu.add_command(label="Ø­ÙˆÙ„", command=lambda: messagebox.showinfo("Ø­ÙˆÙ„", "Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v3.0"))
    menubar.add_cascade(label="Ù…Ø³Ø§Ø¹Ø¯Ø©", menu=help_menu)
    
    root.config(menu=menubar)

def create_advanced_interface():
    global root, notebook, status_var, preview_text, result_display, table_frame
    
    root = tk.Tk()
    root.title("Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v3.0")
    root.geometry("1400x900")
    root.configure(bg=COLORS["dark" if is_dark_mode else "light"]["bg"])
    
    create_advanced_menu()
    create_enhanced_header()
    
    main_frame = tk.Frame(root, bg=COLORS["dark" if is_dark_mode else "light"]["bg"])
    main_frame.pack(fill="both", expand=True, padx=10, pady=10)
    
    notebook = ttk.Notebook(main_frame)
    notebook.pack(fill="both", expand=True)
    
    create_enhanced_analysis_tab()
    create_advanced_visualization_tab()
    create_machine_learning_tab()
    create_statistical_analysis_tab()
    create_data_management_tab()
    
    create_enhanced_status_bar()
    
    return root

def create_enhanced_header():
    header_frame = tk.Frame(root, bg=COLORS["dark" if is_dark_mode else "light"]["header"], height=100)
    header_frame.pack(fill="x", padx=10, pady=5)
    header_frame.pack_propagate(False)
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ø¹ Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª
    title_frame = tk.Frame(header_frame, bg=COLORS["dark" if is_dark_mode else "light"]["header"])
    title_frame.pack(fill="x", padx=20, pady=10)
    
    tk.Label(title_frame, 
             text="ğŸ§  Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v3.0",
             font=("Arial", 24, "bold"), 
             bg=COLORS["dark" if is_dark_mode else "light"]["header"],
             fg=COLORS["dark" if is_dark_mode else "light"]["highlight"]).pack(side="left")
    
    # Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø³Ø±ÙŠØ¹ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    control_frame = tk.Frame(header_frame, bg=COLORS["dark" if is_dark_mode else "light"]["header"])
    control_frame.pack(side="right", padx=20, pady=10)
    
    quick_actions = [
        ("ğŸš€ ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹", quick_analysis),
        ("ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", show_dashboard),
        ("ğŸ¤– Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", machine_learning_predictions),
        ("ğŸ“ˆ ØªØµØ¯ÙŠØ± ØªÙ‚Ø±ÙŠØ±", export_dashboard)
    ]
    
    for text, command in quick_actions:
        btn = tk.Button(control_frame, text=text, font=("Arial", 10), 
                       bg=COLORS["dark" if is_dark_mode else "light"]["button_bg"],
                       fg="white", command=command)
        btn.pack(side="left", padx=5)

def create_enhanced_analysis_tab():
    analysis_tab = ttk.Frame(notebook)
    notebook.add(analysis_tab, text="ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… PanedWindow Ù„Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    main_paned = ttk.PanedWindow(analysis_tab, orient=tk.HORIZONTAL)
    main_paned.pack(fill="both", expand=True, padx=10, pady=10)
    
    # Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„ÙŠØ³Ø±Ù‰ - Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ…
    left_panel = ttk.Frame(main_paned)
    main_paned.add(left_panel, weight=1)
    
    # Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„ÙŠÙ…Ù†Ù‰ - Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    right_panel = ttk.Frame(main_paned)
    main_paned.add(right_panel, weight=2)
    
    create_analysis_control_panel(left_panel)
    create_analysis_results_panel(right_panel)

def create_analysis_control_panel(parent):
    """Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    # Ø¨Ø·Ø§Ù‚Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    load_card = create_card(parent, "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    tk.Button(load_card, text="ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª", command=load_file,
              bg=COLORS["dark" if is_dark_mode else "light"]["button_bg"],
              fg="white", font=("Arial", 11)).pack(fill="x", pady=5)
    
    # Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
    quick_card = create_card(parent, "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹")
    
    quick_actions = [
        ("ğŸ” ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", lambda: show_quality_report(features.detect_data_quality_issues(data_frame)) if data_frame is not None else messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª!")),
        ("âœ¨ ØªÙ†Ø¸ÙŠÙ Ø¢Ù„ÙŠ", automated_data_cleaning),
        ("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©", advanced_statistical_analysis),
        ("ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·", correlation_analysis)
    ]
    
    for text, command in quick_actions:
        tk.Button(quick_card, text=text, command=command,
                 bg=COLORS["dark" if is_dark_mode else "light"]["accent"],
                 fg=COLORS["dark" if is_dark_mode else "light"]["text"]).pack(fill="x", pady=2)
    
    # Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    advanced_card = create_card(parent, "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    advanced_actions = [
        ("â° ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ", time_series_analysis),
        ("ğŸ¯ ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", machine_learning_predictions),
        ("ğŸ“Š Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·", correlation_analysis),
        ("ğŸ” Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·", pattern_detection)
    ]
    
    for text, command in advanced_actions:
        tk.Button(advanced_card, text=text, command=command,
                 bg=COLORS["dark" if is_dark_mode else "light"]["success"]).pack(fill="x", pady=2)

def create_card(parent, title):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø·Ø§Ù‚Ø© ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù…"""
    card = tk.Frame(parent, bg=COLORS["dark" if is_dark_mode else "light"]["card"],
                   relief="raised", bd=1)
    card.pack(fill="x", pady=5, padx=5)
    
    tk.Label(card, text=title, font=("Arial", 12, "bold"),
            bg=COLORS["dark" if is_dark_mode else "light"]["card"]).pack(pady=5)
    
    content_frame = tk.Frame(card, bg=COLORS["dark" if is_dark_mode else "light"]["card"])
    content_frame.pack(fill="x", padx=10, pady=5)
    
    return content_frame

def create_analysis_results_panel(parent):
    """Ù„ÙˆØ­Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    notebook_results = ttk.Notebook(parent)
    notebook_results.pack(fill="both", expand=True)
    
    # ØªØ¨ÙˆÙŠØ¨ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    preview_frame = ttk.Frame(notebook_results)
    notebook_results.add(preview_frame, text="ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    global preview_text
    preview_text = scrolledtext.ScrolledText(preview_frame, font=("Consolas", 10))
    preview_text.pack(fill="both", expand=True, padx=10, pady=10)
    
    # ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results_frame = ttk.Frame(notebook_results)
    notebook_results.add(results_frame, text="ğŸ“ˆ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    global result_display
    result_display = scrolledtext.ScrolledText(results_frame, font=("Arial", 11))
    result_display.pack(fill="both", expand=True, padx=10, pady=10)
    
    # ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¬Ø¯ÙˆÙ„
    global table_frame
    table_frame = ttk.Frame(notebook_results)
    notebook_results.add(table_frame, text="ğŸ“‹ Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„")

def create_advanced_visualization_tab():
    vis_tab = ttk.Frame(notebook)
    notebook.add(vis_tab, text="ğŸ“Š Ø§Ù„ØªØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    tk.Label(vis_tab, text="ğŸ¨ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØµÙˆØ± Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", 
             font=("Arial", 16, "bold")).pack(pady=20)
    
    # Ø´Ø¨ÙƒØ© Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØµÙˆØ±
    viz_frame = tk.Frame(vis_tab)
    viz_frame.pack(fill="both", expand=True, padx=20, pady=10)
    
    visualization_types = [
        ("ğŸ“ˆ Ù…Ø®Ø·Ø·Ø§Øª Ø®Ø·ÙŠØ©", "line"),
        ("ğŸ“Š Ø£Ø¹Ù…Ø¯Ø©", "bar"),
        ("ğŸ”´ Ù…Ø¨Ø¹Ø«Ø±", "scatter"),
        ("ğŸ“¦ ØµÙ†Ø¯ÙˆÙ‚ÙŠ", "box"),
        ("ğŸ» ÙƒÙ…Ø§Ù†ÙŠ", "violin"),
        ("ğŸ”¥ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ©", "heatmap"),
    ]
    
    for i, (text, viz_type) in enumerate(visualization_types):
        row, col = i // 3, i % 3
        btn = tk.Button(viz_frame, text=text, font=("Arial", 10),
                       command=lambda vt=viz_type: create_visualization(vt))
        btn.grid(row=row, column=col, padx=5, pady=5, sticky="ew")
    
    viz_frame.grid_columnconfigure((0,1,2), weight=1)

def create_visualization(viz_type):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙˆØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµÙˆØ±!")
        return
    
    try:
        fig = features.create_advanced_chart(data_frame, viz_type, 
                                           data_frame.columns[0] if len(data_frame.columns) > 0 else None,
                                           data_frame.columns[1] if len(data_frame.columns) > 1 else None)
        if fig:
            plt.show()
        else:
            messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù…: {str(e)}")

def create_machine_learning_tab():
    ml_tab = ttk.Frame(notebook)
    notebook.add(ml_tab, text="ğŸ¤– Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    tk.Label(ml_tab, text="ğŸ§  Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", 
             font=("Arial", 16, "bold")).pack(pady=20)
    
    ml_frame = tk.Frame(ml_tab)
    ml_frame.pack(fill="both", expand=True, padx=20, pady=10)
    
    ml_algorithms = [
        ("ğŸ“ˆ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ", "linear_regression"),
        ("ğŸŒ³ Ø§Ù„ØºØ§Ø¨Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©", "random_forest"),
        ("ğŸ” Ø§Ù„ØªØ¬Ù…ÙŠØ¹", "kmeans"),
        ("ğŸ“Š Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ", "logistic_regression"),
    ]
    
    for i, (text, algo) in enumerate(ml_algorithms):
        row, col = i // 2, i % 2
        btn = tk.Button(ml_frame, text=text, font=("Arial", 10),
                       command=lambda a=algo: run_advanced_ml(a))
        btn.grid(row=row, column=col, padx=5, pady=5, sticky="ew")
    
    ml_frame.grid_columnconfigure((0,1), weight=1)

def run_advanced_ml(algorithm):
    """ØªØ´ØºÙŠÙ„ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""
    machine_learning_predictions()

def create_statistical_analysis_tab():
    stats_tab = ttk.Frame(notebook)
    notebook.add(stats_tab, text="ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    tk.Label(stats_tab, text="ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…", 
             font=("Arial", 16, "bold")).pack(pady=20)
    
    stats_frame = tk.Frame(stats_tab)
    stats_frame.pack(fill="both", expand=True, padx=20, pady=10)
    
    statistical_tests = [
        ("ğŸ“ Ø§Ø®ØªØ¨Ø§Ø± T", "t_test"),
        ("ğŸ“ ANOVA", "anova"),
        ("ğŸ“Š Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§ÙŠ squared", "chi_square"),
        ("ğŸ“ˆ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±", "regression"),
        ("ğŸ“‰ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·", "correlation"),
        ("ğŸ“‹ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ", "descriptive")
    ]
    
    for i, (text, test) in enumerate(statistical_tests):
        row, col = i // 3, i % 3
        btn = tk.Button(stats_frame, text=text, font=("Arial", 10),
                       command=lambda t=test: run_statistical_test(t))
        btn.grid(row=row, column=col, padx=5, pady=5, sticky="ew")
    
    stats_frame.grid_columnconfigure((0,1,2), weight=1)

def run_statistical_test(test_type):
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©"""
    if test_type == "descriptive":
        advanced_statistical_analysis()
    elif test_type == "correlation":
        correlation_analysis()
    else:
        messagebox.showinfo("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", f"Ø§Ø®ØªØ¨Ø§Ø± {test_type} Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±")

def create_data_management_tab():
    data_tab = ttk.Frame(notebook)
    notebook.add(data_tab, text="ğŸ’¾ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    tk.Label(data_tab, text="ğŸ› ï¸ Ø£Ø¯ÙˆØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", 
             font=("Arial", 16, "bold")).pack(pady=20)
    
    management_frame = tk.Frame(data_tab)
    management_frame.pack(fill="both", expand=True, padx=20, pady=10)
    
    management_tools = [
        ("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", automated_data_cleaning),
        ("ğŸ”§ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª", advanced_feature_engineering),
        ("ğŸ’¾ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ", backup_data),
        ("ğŸ“Š ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", transform_data),
        ("ğŸ” ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø©", lambda: show_quality_report(features.detect_data_quality_issues(data_frame)) if data_frame is not None else messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª!"))
    ]
    
    for i, (text, command) in enumerate(management_tools):
        row, col = i // 3, i % 3
        btn = tk.Button(management_frame, text=text, font=("Arial", 10), command=command)
        btn.grid(row=row, column=col, padx=5, pady=5, sticky="ew")
    
    management_frame.grid_columnconfigure((0,1,2), weight=1)

def import_export_data():
    """Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    messagebox.showinfo("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "Ø£Ø¯Ø§Ø© Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯/Ø§Ù„ØªØµØ¯ÙŠØ± Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±")

def backup_data():
    """Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        if data_frame is not None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"backup_data_{timestamp}.csv"
            data_frame.to_csv(backup_file, index=False)
            messagebox.showinfo("Ù†Ø¬Ø§Ø­", f"ØªÙ… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¥Ù„Ù‰: {backup_file}")
        else:
            messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", f"ÙØ´Ù„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {str(e)}")

def transform_data():
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    if data_frame is None:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­ÙˆÙŠÙ„!")
        return
    
    transform_window = tk.Toplevel(root)
    transform_window.title("ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    transform_window.geometry("300x200")
    
    transforms = [
        ("Normalization", normalize_data),
        ("Standardization", standardize_data),
        ("Log Transform", log_transform)
    ]
    
    for text, command in transforms:
        tk.Button(transform_window, text=text, command=command).pack(pady=5)

def create_enhanced_status_bar():
    global status_var
    
    status_frame = tk.Frame(root, bg=COLORS["dark" if is_dark_mode else "light"]["accent"])
    status_frame.pack(fill="x", side="bottom")
    
    status_var = tk.StringVar()
    status_var.set("âœ… Ø¬Ø§Ù‡Ø² - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… v3.0")
    
    status_label = tk.Label(status_frame, textvariable=status_var, 
                           font=("Arial", 10),
                           bg=COLORS["dark" if is_dark_mode else "light"]["accent"],
                           fg=COLORS["dark" if is_dark_mode else "light"]["text"])
    status_label.pack(side="left", padx=10, pady=2)
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    system_info = f"Python {platform.python_version()} | {platform.system()}"
    system_label = tk.Label(status_frame, text=system_info, font=("Arial", 9))
    system_label.pack(side="right", padx=10, pady=2)

def show_dashboard():
    """Ø¹Ø±Ø¶ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    dashboard_window = tk.Toplevel(root)
    dashboard_window.title("Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Dashboard")
    dashboard_window.geometry("1000x700")
    
    tk.Label(dashboard_window, text="ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©", 
             font=("Arial", 20, "bold")).pack(pady=20)
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
    if data_frame is not None:
        stats_text = f"""
        ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
        â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {data_frame.shape[0]:,}
        â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {data_frame.shape[1]}
        â€¢ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {data_frame.isnull().sum().sum():,}
        â€¢ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {data_frame.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB
        """
        tk.Label(dashboard_window, text=stats_text, font=("Arial", 12), justify="left").pack()
    else:
        tk.Label(dashboard_window, text="âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø©", font=("Arial", 14)).pack()

def update_data_preview():
    if data_frame is not None and 'preview_text' in globals():
        preview_text.delete(1.0, tk.END)
        preview_rows = user_preferences.get("data_preview_rows", 15)
        preview_text.insert(tk.END, data_frame.head(preview_rows).to_string())

def quick_analysis():
    if data_frame is not None:
        advanced_statistical_analysis()
    else:
        messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„!")

def update_status(msg):
    """ØªØ­Ø¯ÙŠØ« Ø´Ø±ÙŠØ· Ø§Ù„Ø­Ø§Ù„Ø©"""
    global status_var
    if 'status_var' in globals():
        status_var.set(msg)

# ------------------- Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ -------------------
def main():
    global root
    root = create_advanced_interface()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    try:
        if os.path.exists("data_analysis_settings.json"):
            with open("data_analysis_settings.json", "r", encoding='utf-8') as f:
                loaded_settings = json.load(f)
                user_preferences.update(loaded_settings)
    except:
        pass
    
    root.mainloop()

if __name__ == "__main__":
    main()